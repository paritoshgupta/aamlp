{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor flow version --> 2.2.0\n",
      "Keras version --> 2.3.0-tf\n"
     ]
    }
   ],
   "source": [
    "# !pip install efficientnet\n",
    "# !pip install pydot\n",
    "# !pip install graphviz\n",
    "# !pip install pydotplus\n",
    "import tqdm\n",
    "from tqdm import tqdm_notebook\n",
    "import math\n",
    "from PIL import Image\n",
    "import pydot\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow.keras.backend as K\n",
    "import pydotplus\n",
    "from pydotplus import graphviz\n",
    "import pydot\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras.utils.data_utils import Sequence\n",
    "import efficientnet.tfkeras as efn\n",
    "from keras.applications import VGG16\n",
    "\n",
    "# BytesList = tf.train.BytesList\n",
    "# FloatList = tf.train.FloatList\n",
    "# Int64List = tf.train.Int64List\n",
    "# Feature = tf.train.Feature\n",
    "# Features = tf.train.Features\n",
    "# Example = tf.train.Example\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "# np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "\n",
    "print(f\"Tensor flow version --> {tf.__version__}\")\n",
    "# from tensorflow.keras.utils import Sequence\n",
    "print(f\"Keras version --> {keras.__version__}\")\n",
    "\n",
    "\n",
    "\n",
    "OUTPUT_PATH = \"/Users/paritoshgupta/Desktop/aamlp/aamlp/input/osic-pulmonary-fibrosis-progression/ads/\"\n",
    "OUTPUT_PATH_LUNG_MASK_IMAGES_1MM = \"/Users/paritoshgupta/Desktop/aamlp/aamlp/input/osic-pulmonary-fibrosis-progression/ads/lung_mask_1mm/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hideCode": true
   },
   "outputs": [],
   "source": [
    "# # C1, C2 = tf.constant(70, dtype='float32'), tf.constant(1000, dtype=\"float32\")\n",
    "# # def score(y_true, y_pred):\n",
    "# #     tf.dtypes.cast(y_true, tf.float32)\n",
    "# #     tf.dtypes.cast(y_pred, tf.float32)\n",
    "# #     sigma = y_pred[:, 2] - y_pred[:, 0]\n",
    "# #     fvc_pred = y_pred[:, 1]\n",
    "    \n",
    "# #     #sigma_clip = sigma + C1\n",
    "# #     sigma_clip = tf.maximum(sigma, C1)\n",
    "# #     delta = tf.abs(y_true[:, 0] - fvc_pred)\n",
    "# #     delta = tf.minimum(delta, C2)\n",
    "# #     sq2 = tf.sqrt( tf.dtypes.cast(2, dtype=tf.float32) )\n",
    "# #     metric = (delta / sigma_clip)*sq2 + tf.math.log(sigma_clip* sq2)\n",
    "# #     return keras.backend.mean(metric)\n",
    "\n",
    "# # def qloss(y_true, y_pred):\n",
    "# #     # Pinball loss for multiple quantiles\n",
    "# #     qs = [0.2, 0.50, 0.8]\n",
    "# #     q = tf.constant(np.array([qs]), dtype=tf.float32)\n",
    "# #     e = y_true - y_pred\n",
    "# #     v = tf.maximum(q*e, (q-1)*e)\n",
    "# #     return keras.backend.mean(v)\n",
    "\n",
    "# # def mloss(_lambda):\n",
    "# #     def loss(y_true, y_pred):\n",
    "# #         return _lambda * qloss(y_true, y_pred) + (1 - _lambda)*score(y_true, y_pred)\n",
    "# #     return loss\n",
    "\n",
    "\n",
    "# # def get_efficientnet(model, shape):\n",
    "# #     models_dict = {\n",
    "# #         'b0': efn.EfficientNetB0(input_shape=shape,weights=None,include_top=False),\n",
    "# #         'b1': efn.EfficientNetB1(input_shape=shape,weights=None,include_top=False),\n",
    "# #         'b2': efn.EfficientNetB2(input_shape=shape,weights=None,include_top=False),\n",
    "# #         'b3': efn.EfficientNetB3(input_shape=shape,weights=None,include_top=False),\n",
    "# #         'b4': efn.EfficientNetB4(input_shape=shape,weights=None,include_top=False),\n",
    "# #         'b5': efn.EfficientNetB5(input_shape=shape,weights=None,include_top=False),\n",
    "# #         'b6': efn.EfficientNetB6(input_shape=shape,weights=None,include_top=False),\n",
    "# #         'b7': efn.EfficientNetB7(input_shape=shape,weights=None,include_top=False)\n",
    "# #     }\n",
    "# #     return models_dict[model]\n",
    "\n",
    "\n",
    "# # # def build_model(input_shape_image, model_class = None):\n",
    "# # #     image_inp = keras.layers.Input(shape=input_shape_image, name=\"input_image\")\n",
    "# # #     layer_model_head = get_efficientnet(model_class, input_shape_image)(image_inp)    \n",
    "# # #     layer_model_head.trainable = False\n",
    "# # #     layer_global_pooling = keras.layers.GlobalAveragePooling2D(name=\"pretrained_global_avg_pooling\")(layer_model_head)\n",
    "# # #     layer_global_pooling_out =keras.layers.Dense(320, activation=\"relu\", name=\"global_pooling_out\")(layer_global_pooling)\n",
    "# # #     dropout_img_1 = keras.layers.Dropout(0.5, name=\"dropout_img_1\")(layer_global_pooling_out)\n",
    "# # # #     dense_layer_image_1 = keras.layers.Dense(64, activation=\"relu\", name=\"global_pooling_out\")(layer_global_pooling)\n",
    "# # # #     dropout_img_2 = keras.layers.Dropout(0.3, name=\"dropout_img_2\")(dense_layer_image_1)\n",
    "# # #     out_image = keras.layers.Dense(16, activation =\"relu\", name =\"output_class\")(dropout_img_1)\n",
    "    \n",
    "# # #     tabular_inp= keras.layers.Input(shape=(8,))\n",
    "# # #     concat = keras.layers.Concatenate(name=\"concat\")([out_image, tabular_inp])\n",
    "# # #     concat_out_1 = keras.layers.Dense(512, activation=\"relu\", name=\"concat_out_1\")(concat)\n",
    "# # #     drop_out_img_tab_1 = keras.layers.Dropout(0.4, name=\"dropout_img_tab_1\")(concat_out_1)\n",
    "# # #     concat_out_2 = keras.layers.Dense(256, activation=\"relu\", name=\"concat_out_2\")(drop_out_img_tab_1)\n",
    "# # #     drop_out_img_tab_2 = keras.layers.Dropout(0.3, name=\"dropout_img_tab_2\")(concat_out_2)\n",
    "# # #     concat_out_3 = keras.layers.Dense(100, activation=\"relu\", name=\"concat_out_3\")(drop_out_img_tab_2)\n",
    "# # #     p1 = keras.layers.Dense(3, activation=\"linear\", name=\"p1\")(concat_out_3)\n",
    "# # #     p2 = keras.layers.Dense(3, activation=\"relu\", name=\"p2\")(concat_out_3)\n",
    "# # #     preds = keras.layers.Lambda(lambda x: x[0] + tf.cumsum(x[1], axis=1), \n",
    "# # #                      name=\"preds\")([p1, p2])\n",
    "    \n",
    "# # #     model = keras.Model(inputs = [image_inp, tabular_inp], outputs = preds)\n",
    "# # #     return model\n",
    "\n",
    "# class DataGenerator(Sequence):\n",
    "#     def __init__(self, dataset, batch_size=16,  shuffle=True):\n",
    "#         'Initialization'\n",
    "#         self.batch_size = batch_size\n",
    "#         self.dataset = dataset\n",
    "#         self.shuffle = shuffle\n",
    "#         self.indexes = dataset.index\n",
    "# #         self.on_epoch_end()\n",
    " \n",
    "#     def __len__(self):\n",
    "#         'Denotes the number of batches per epoch'\n",
    "#         return math.ceil(len(self.dataset) / self.batch_size)\n",
    " \n",
    "#     def __getitem__(self, index):\n",
    "#         'Generate one batch of data'\n",
    "#         # Generate indexes of the batch\n",
    "#         idxs = [i for i in range(index*self.batch_size,(index+1)*self.batch_size)]\n",
    " \n",
    "#         # Find list of IDs\n",
    "#         ids_tmp = [self.indexes[k] for k in idxs]\n",
    "        \n",
    "#         # Generate data\n",
    "#         # tabular\n",
    "#         tab = self.dataset.loc[ids_tmp, ['Male', 'Female', 'Ex-smoker', 'Never smoked', 'Currently smokes', 'age', 'week', 'base_fvc']].to_numpy()#.reshape(-1)\n",
    "        \n",
    "#         # image\n",
    "#         patient_ids = list(self.dataset.loc[ids_tmp, 'Patient'].to_numpy())\n",
    "        \n",
    "#         imgs_master = []\n",
    "#         for pat_id in patient_ids:\n",
    "#             images = os.listdir(os.path.join(OUTPUT_PATH_LUNG_MASK_IMAGES_1MM, pat_id))\n",
    "#             sorted_images = sorted(images,key=lambda x: int(os.path.splitext(x)[0]))\n",
    "#             slices = [Image.open(f\"{OUTPUT_PATH_LUNG_MASK_IMAGES_1MM}/{pat_id}/{sorted_images[index]}\").convert('L') for index, file in enumerate(sorted_images)]\n",
    "#             tmp_array = np.mean([np.array(slices[i]) for i in range(int(len(slices)/4), int(len(slices)/2))], axis=0)\n",
    "#             out = cv2.resize(tmp_array, dsize=(512, 512), interpolation=cv2.INTER_CUBIC)\n",
    "#             imgs_master.append(out)\n",
    "            \n",
    "#         imgs_master = np.array(imgs_master)\n",
    "#         imgs_master_out = np.expand_dims(imgs_master, axis=-1)\n",
    "        \n",
    "#         # target column\n",
    "#         FVC = self.dataset.loc[ids_tmp, 'FVC'].to_numpy()\n",
    "        \n",
    "#     #print(\"u,i,r:\", [User, Item],[y])\n",
    "#         return [imgs_master_out, tab], FVC\n",
    " \n",
    "#     def on_epoch_end(self):\n",
    "#         'Updates indexes after each epoch'\n",
    "#         self.indexes = np.arange(len(self.dataset))\n",
    "#         if self.shuffle == True:\n",
    "#             self.indexes = np.random.shuffle(self.indexes)\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hideCode": true
   },
   "outputs": [],
   "source": [
    "# model = build_model(input_shape_image = (512, 512, 1), model_class=\"b0\")\n",
    "# df_folds = pd.read_csv(f\"{OUTPUT_PATH}/osic_folds.csv\")\n",
    "\n",
    "# def run(fold):\n",
    "#     df_train = df_folds[df_folds.fold !=fold].reset_index(drop=True)\n",
    "#     # get validation data\n",
    "#     df_valid = df_folds[df_folds.fold==fold].reset_index(drop=True)\n",
    "    \n",
    "#     model.fit(DataGenerator(dataset=df_train), validation_data=DataGenerator(dataset=df_valid), verbose=1)\n",
    "    \n",
    "#     print(\"val\", model.evaluate(DataGenerator(dataset=df_valid), verbose=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xception Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROT_ = 0\n",
    "SHR_ = 2.0\n",
    "HZOOM_ = 2\n",
    "WZOOM_ = 4\n",
    "HSHIFT_ = 2\n",
    "WSHIFT_ = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "# def build_model(input_shape_image):\n",
    "    \n",
    "#     input_image = keras.layers.Input(shape=input_shape_image, name=\"Image_Input\")\n",
    "    \n",
    "#     base_model = keras.applications.xception.Xception(weights=\"imagenet\", include_top=False,\n",
    "#                 input_tensor=keras.layers.Input(shape=input_shape_image))\n",
    "#     base_model_output = base_model(input_image)\n",
    "#     print(f\"Number of layers in pre trained model --> {len(base_model.layers)}\")\n",
    "    \n",
    "# #     base_model = keras.applications.xception.Xception(weights=\"imagenet\", include_top=False)\n",
    "# #     global average pooling 2d\n",
    "#     layer_global_pooling = keras.layers.GlobalAveragePooling2D(name=\"pretrained_global_avg_pooling\")(base_model_output)\n",
    "    \n",
    "# #     layer_global_pooling_out =keras.layers.Dense(32, activation=\"relu\", name=\"global_pooling_out\")(layer_global_pooling)\n",
    "# #     dropout_img_1 = keras.layers.Dropout(0.3, name=\"dropout_img_1\")(layer_next_flattenning)\n",
    "# #     concat_out_1 = keras.layers.Dense(128, activation=\"relu\", name=\"concat_out_1\")(concat)\n",
    "# #     drop_out_img_tab_1 = keras.layers.Dropout(0.3, name=\"dropout_img_tab_1\")(concat_out_1)\n",
    "\n",
    "#     # flatten, dropout, dense for image (Image Network)\n",
    "# #     average_pooling_2d = keras.layers.GlobalAveragePooling2D(pool_size=(2,2), name=\"AvgPool2d\")(base_model_output)\n",
    "# #     layer_global_pooling = keras.layers.GlobalAveragePooling2D(name=\"pretrained_global_avg_pooling\")(base_model_output)\n",
    "# #     layer_flattening = keras.layers.Flatten(name=\"Flattening\")(layer_global_pooling)\n",
    "# #     layer_next_flattenning =keras.layers.Dense(128, activation=\"relu\", name=\"Next_Flattening\")(layer_global_pooling)\n",
    "#     dropout_img_1 = keras.layers.Dropout(0.5, name=\"dropout_img_1\")(layer_global_pooling)\n",
    "# #     dropout_img_2 = keras.layers.Dropout(0.25, name=\"dropout_img_2\")(layer_next_flattenning)\n",
    "#     out_image = keras.layers.Dense(32, name =\"output_class\",activation=\"relu\")(dropout_img_1)  \n",
    "    \n",
    "    \n",
    "#     # Tabular Input\n",
    "#     tabular_inp= keras.layers.Input(shape=(8,))\n",
    "    \n",
    "#     # Concat - Image and Tabular\n",
    "#     concat = keras.layers.Concatenate(name=\"concat\")([out_image, tabular_inp])\n",
    "#     concat_out_1 = keras.layers.Dense(32, name=\"concat_out_2\", activation=\"relu\",\n",
    "#                                      kernel_regularizer=keras.regularizers.l2(0.05))(concat)\n",
    "#     drop_out_img_tab_1 = keras.layers.Dropout(0.2, name=\"dropout_img_tab_2\")(concat_out_1)\n",
    "#     concat_out_2 = keras.layers.Dense(16, name=\"concat_out_3\", activation=\"relu\")(drop_out_img_tab_1)\n",
    "#     p1 = keras.layers.Dense(3, activation=\"linear\", name=\"p1\")(concat_out_2)\n",
    "#     p2 = keras.layers.Dense(3, activation=\"relu\", name=\"p2\")(concat_out_2)\n",
    "#     preds = keras.layers.Lambda(lambda x: x[0] + tf.cumsum(x[1], axis=1), \n",
    "#                      name=\"preds\")([p1, p2])\n",
    "    \n",
    "#     model = keras.Model(inputs = [input_image, tabular_inp], outputs = preds)\n",
    "#     for layer in base_model.layers:\n",
    "#         layer.trainable = False\n",
    "        \n",
    "#     return base_model, model\n",
    "\n",
    "def get_mat(rotation, shear, height_zoom, width_zoom, height_shift, width_shift):\n",
    "    # returns 3x3 transformmatrix which transforms indicies\n",
    "        \n",
    "    # CONVERT DEGREES TO RADIANS\n",
    "    rotation = math.pi * rotation / 180.\n",
    "    shear = math.pi * shear / 180.\n",
    "    \n",
    "    # ROTATION MATRIX\n",
    "    c1 = tf.math.cos(rotation)\n",
    "    s1 = tf.math.sin(rotation)\n",
    "    one = tf.constant([1],dtype='float32')\n",
    "    zero = tf.constant([0],dtype='float32')\n",
    "    rotation_matrix = tf.reshape( tf.concat([c1,s1,zero, -s1,c1,zero, zero,zero,one],axis=0),[3,3] )\n",
    "        \n",
    "    # SHEAR MATRIX\n",
    "    c2 = tf.math.cos(shear)\n",
    "    s2 = tf.math.sin(shear)\n",
    "    shear_matrix = tf.reshape( tf.concat([one,s2,zero, zero,c2,zero, zero,zero,one],axis=0),[3,3] )    \n",
    "    \n",
    "    # ZOOM MATRIX\n",
    "    zoom_matrix = tf.reshape( tf.concat([one/height_zoom,zero,zero, zero,one/width_zoom,zero, zero,zero,one],axis=0),[3,3] )\n",
    "    \n",
    "    # SHIFT MATRIX\n",
    "    shift_matrix = tf.reshape( tf.concat([one,zero,height_shift, zero,one,width_shift, zero,zero,one],axis=0),[3,3] )\n",
    "    \n",
    "    return K.dot(K.dot(rotation_matrix, shear_matrix), K.dot(zoom_matrix, shift_matrix))\n",
    "\n",
    "\n",
    "def transform(image, image_size):\n",
    "    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n",
    "    # output - image randomly rotated, sheared, zoomed, and shifted\n",
    "    DIM = image_size[0]\n",
    "    XDIM = DIM%2 #fix for size 331\n",
    "    \n",
    "    rot = ROT_ * tf.random.normal([1], dtype='float32')\n",
    "    shr = SHR_ * tf.random.normal([1], dtype='float32') \n",
    "    h_zoom = 1.0 + tf.random.normal([1], dtype='float32') / HZOOM_\n",
    "    w_zoom = 1.0 + tf.random.normal([1], dtype='float32') / WZOOM_\n",
    "    h_shift = HSHIFT_ * tf.random.normal([1], dtype='float32') \n",
    "    w_shift = WSHIFT_ * tf.random.normal([1], dtype='float32') \n",
    "\n",
    "    # GET TRANSFORMATION MATRIX\n",
    "    m = get_mat(rot,shr,h_zoom,w_zoom,h_shift,w_shift) \n",
    "\n",
    "    # LIST DESTINATION PIXEL INDICES\n",
    "    x = tf.repeat( tf.range(DIM//2,-DIM//2,-1), DIM )\n",
    "    y = tf.tile( tf.range(-DIM//2,DIM//2),[DIM] )\n",
    "    z = tf.ones([DIM*DIM],dtype='int32')\n",
    "    \n",
    "    idx = tf.stack([x,y,z])    \n",
    "    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n",
    "    idx2 = K.dot(m,tf.cast(idx,dtype='float32'))\n",
    "    idx2 = K.cast(idx2,dtype='int32')\n",
    "    idx2 = K.clip(idx2,-DIM//2+XDIM+1,DIM//2)\n",
    "\n",
    "    \n",
    "    # FIND ORIGIN PIXEL VALUES           \n",
    "    idx3 = tf.stack( [DIM//2-idx2[0,], DIM//2-1+idx2[1,]] )\n",
    "    d = tf.gather_nd(image,tf.transpose(idx3))\n",
    "        \n",
    "    return tf.reshape(d,[DIM,DIM,3])\n",
    "\n",
    "\n",
    "def score(y_true, y_pred):\n",
    "    C1 = tf.constant(70, dtype='float32')\n",
    "    C2 = tf.constant(1000, dtype=\"float32\")\n",
    "    tf.dtypes.cast(y_true, tf.float32)\n",
    "    tf.dtypes.cast(y_pred, tf.float32)\n",
    "    sigma = y_pred[:, 2] - y_pred[:, 0]\n",
    "    fvc_pred = y_pred[:, 1]\n",
    "    \n",
    "    #sigma_clip = sigma + C1\n",
    "    sigma_clip = tf.maximum(sigma, C1)\n",
    "    delta = tf.abs(y_true[:, 0] - fvc_pred)\n",
    "    delta = tf.minimum(delta, C2)\n",
    "    sq2 = tf.sqrt( tf.dtypes.cast(2, dtype=tf.float32) )\n",
    "    metric = (delta / sigma_clip)*sq2 + tf.math.log(sigma_clip* sq2)\n",
    "    return keras.backend.mean(metric)\n",
    "\n",
    "def qloss(y_true, y_pred):\n",
    "    # Pinball loss for multiple quantiles\n",
    "    qs = [0.2, 0.50, 0.8]\n",
    "    q = tf.constant(np.array([qs]), dtype=tf.float32)\n",
    "    e = y_true - y_pred\n",
    "    v = tf.maximum(q*e, (q-1)*e)\n",
    "    return keras.backend.mean(v)\n",
    "\n",
    "def mloss(_lambda):\n",
    "    def loss(y_true, y_pred):\n",
    "        return _lambda * qloss(y_true, y_pred) + (1 - _lambda)*score(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "def convert_to_tensor(arg):\n",
    "    out = tf.convert_to_tensor(arg, dtype=tf.float32)\n",
    "    return out\n",
    "\n",
    "def plot_image(image):\n",
    "    plt.imshow(image, cmap=\"gray\", interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")    \n",
    "\n",
    "def plot_color_image(image):\n",
    "    plt.imshow(image, interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "def central_crop(image):\n",
    "    shape = tf.shape(image)\n",
    "    min_dim = tf.reduce_min([shape[0], shape[1]])\n",
    "    top_crop = (shape[0] - min_dim) // 4\n",
    "    bottom_crop = shape[0] - top_crop\n",
    "    left_crop = (shape[1] - min_dim) // 4\n",
    "    right_crop = shape[1] - left_crop\n",
    "    return image[top_crop:bottom_crop, left_crop:right_crop]\n",
    "\n",
    "def random_crop(image):\n",
    "    shape = tf.shape(image)\n",
    "    min_dim = tf.reduce_min([shape[0], shape[1]]) * 90 // 100\n",
    "    return tf.image.random_crop(image, [min_dim, min_dim, 3])\n",
    "\n",
    "def preprocess(image):\n",
    "    resized_image = tf.image.resize(image, [224, 224])\n",
    "    final_image = keras.applications.vgg19.preprocess_input(resized_image*255)\n",
    "    \n",
    "    return final_image\n",
    "\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, dataset, batch_size, aug, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.batch_size = batch_size\n",
    "        self.aug = aug\n",
    "        self.dataset = dataset\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(self.dataset.shape[0])\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(self.dataset.shape[0]/self.batch_size))\n",
    " \n",
    "    def __getitem__(self, index):\n",
    "        # Generate indexes of the batch\n",
    "        idxs = [i for i in range(index*self.batch_size,(index+1)*self.batch_size)]\n",
    " \n",
    "        # Find list of IDs\n",
    "        ids_tmp = [self.indexes[k] for k in idxs]\n",
    "        \n",
    "        # Generate data\n",
    "        # tabular\n",
    "        tab = self.dataset.loc[ids_tmp, ['Male', 'Female', 'Ex-smoker', 'Never smoked', \n",
    "                                         'Currently smokes', 'age', 'week', 'base_fvc']].to_numpy(dtype=np.float32)\n",
    "        \n",
    "        # image\n",
    "        patient_ids = list(self.dataset.loc[ids_tmp, 'Patient'])\n",
    "        imgs_master = []\n",
    "        \n",
    "        for pat_id in patient_ids:    \n",
    "            images = os.listdir(os.path.join(OUTPUT_PATH_LUNG_MASK_IMAGES_1MM, pat_id))\n",
    "            sorted_images = sorted(images,key=lambda x: int(os.path.splitext(x)[0]))\n",
    "            slices = [Image.open(f\"{OUTPUT_PATH_LUNG_MASK_IMAGES_1MM}/{pat_id}/{sorted_images[index]}\").convert('L') for index, file in enumerate(sorted_images)]    \n",
    "            \n",
    "            \n",
    "            ######## OLD ########\n",
    "#             img1 = np.mean([np.array(slices[i]) for i in range(int(0.15 * len(slices)), int(0.4 * len(slices)))], axis=0)/255\n",
    "#             img1 = tf.convert_to_tensor(img1.reshape((*img1.shape, 1)))\n",
    "#             img2 = np.mean([np.array(slices[i]) for i in range(int(0.4 * len(slices)/2), int(0.65 * len(slices)))], axis=0)/255\n",
    "#             img2 = tf.convert_to_tensor(img2.reshape((*img2.shape, 1)))\n",
    "#             img3 = np.mean([np.array(slices[i]) for i in range(int(0.65 * len(slices)), int(0.9 * len(slices)))], axis=0)/255\n",
    "#             img3 = tf.convert_to_tensor(img3.reshape((*img3.shape, 1)))\n",
    "\n",
    "#             randint = np.random.randint(0,3)\n",
    "#             if randint == 0:\n",
    "#                 img_to_resize = img1\n",
    "#             elif randint == 1:\n",
    "#                 img_to_resize = img2\n",
    "#             else:\n",
    "#                 img_to_resize = img3\n",
    "\n",
    "            ######## NEW Augementation (Chris Deotte NB) ########\n",
    "            index = int(len(slices)/3.33)\n",
    "            img1 = np.array(slices[index])/255\n",
    "            img_to_resize = tf.convert_to_tensor(img1.reshape((*img1.shape, 1)))\n",
    "            \n",
    "            images = np.array([img_to_resize]*3)\n",
    "            images_reduced_mean = tf.reduce_mean(images, axis=3)\n",
    "            image_pre_proc = tf.stack([images_reduced_mean[0], images_reduced_mean[1], images_reduced_mean[2]], axis=-1)\n",
    "\n",
    "            # With Augmentation (Training time)\n",
    "            if self.aug:\n",
    "                trans_image = transform(image_pre_proc, image_size = image_pre_proc.shape)\n",
    "                resized_image = preprocess(trans_image)[:, :, 0]\n",
    "            else:\n",
    "                resized_image = preprocess(image_pre_proc)[:, :, 0]\n",
    "                \n",
    "            out_img = tf.stack([resized_image, resized_image, resized_image], axis=-1)\n",
    "            imgs_master.append(out_img)\n",
    "                        \n",
    "        imgs_master_out = tf.stack(imgs_master)\n",
    "\n",
    "        # target column\n",
    "        FVC = self.dataset.loc[ids_tmp, 'FVC'].to_numpy(dtype=np.float32)\n",
    "\n",
    "        # to tensor convert\n",
    "        FVC = convert_to_tensor(tf.constant(FVC))\n",
    "        tab = convert_to_tensor(tf.constant(tab))\n",
    "        \n",
    "        return [imgs_master_out, tab], FVC\n",
    " \n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(self.dataset.shape[0])\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "#         if self.shuffle:\n",
    "#             np.random.shuffle(self.indexes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "# resnet_model = keras.applications.xception(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "#     base_model = keras.applications.xception.Xception(weights=\"imagenet\", include_top=False)\n",
    "#     global average pooling 2d\n",
    "# layer_global_pooling = keras.layers.GlobalAveragePooling2D(name=\"pretrained_global_avg_pooling\")(base_model_output)\n",
    "#     layer_global_pooling_out =keras.layers.Dense(32, activation=\"relu\", name=\"global_pooling_out\")(layer_global_pooling)\n",
    "#     dropout_img_1 = keras.layers.Dropout(0.3, name=\"dropout_img_1\")(layer_next_flattenning)\n",
    "#     concat_out_1 = keras.layers.Dense(128, activation=\"relu\", name=\"concat_out_1\")(concat)\n",
    "#     drop_out_img_tab_1 = keras.layers.Dropout(0.3, name=\"dropout_img_tab_1\")(concat_out_1)\n",
    "\n",
    "# flatten, dropout, dense for image (Image Network)\n",
    "#     average_pooling_2d = keras.layers.GlobalAveragePooling2D(pool_size=(2,2), name=\"AvgPool2d\")(base_model_output)\n",
    "#     layer_global_pooling = keras.layers.GlobalAveragePooling2D(name=\"pretrained_global_avg_pooling\")(base_model_output)\n",
    "#     layer_flattening = keras.layers.Flatten(name=\"Flattening\")(layer_global_pooling)\n",
    "#     layer_next_flattenning =keras.layers.Dense(128, activation=\"relu\", name=\"Next_Flattening\")(layer_global_pooling)\n",
    "# dropout_img_1 = keras.layers.Dropout(0.5, name=\"dropout_img_1\")(layer_global_pooling)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Image_Input (InputLayer)        [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "xception (Model)                (None, 7, 7, 2048)   20861480    Image_Input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "pretrained_global_avg_pooling ( (None, 2048)         0           xception[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "output_dense_img_1 (Dense)      (None, 64)           131136      pretrained_global_avg_pooling[0][\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 64)           256         output_dense_img_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_img_1 (Dropout)         (None, 64)           0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "output_dense_img_2 (Dense)      (None, 16)           1040        dropout_img_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "input_20 (InputLayer)           [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concat (Concatenate)            (None, 24)           0           output_dense_img_2[0][0]         \n",
      "                                                                 input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concat_out_2 (Dense)            (None, 64)           1600        concat[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 64)           256         concat_out_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_img_tab_2 (Dropout)     (None, 64)           0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concat_out_3 (Dense)            (None, 32)           2080        dropout_img_tab_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "p1 (Dense)                      (None, 3)            99          concat_out_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "p2 (Dense)                      (None, 3)            99          concat_out_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "preds (Lambda)                  (None, 3)            0           p1[0][0]                         \n",
      "                                                                 p2[0][0]                         \n",
      "==================================================================================================\n",
      "Total params: 20,998,046\n",
      "Trainable params: 136,310\n",
      "Non-trainable params: 20,861,736\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      " N Layers of BASE model --> 132\n",
      " N Layers of our model --> 16\n",
      "0 Image_Input\n",
      "1 xception\n",
      "2 pretrained_global_avg_pooling\n",
      "3 output_dense_img_1\n",
      "4 batch_normalization_20\n",
      "5 dropout_img_1\n",
      "6 output_dense_img_2\n",
      "7 input_20\n",
      "8 concat\n",
      "9 concat_out_2\n",
      "10 batch_normalization_21\n",
      "11 dropout_img_tab_2\n",
      "12 concat_out_3\n",
      "13 p1\n",
      "14 p2\n",
      "15 preds\n"
     ]
    }
   ],
   "source": [
    "input_shape_image=(224,224,3)\n",
    "input_image = keras.layers.Input(shape=input_shape_image, name=\"Image_Input\")\n",
    "\n",
    "########## Im,age Input ##########\n",
    "# base_model = keras.applications.VGG19(weights=\"imagenet\", include_top=False,\n",
    "#             input_tensor=keras.layers.Input(shape=input_shape_image))\n",
    "base_model = keras.applications.xception.Xception(weights='imagenet', include_top=False, input_shape=input_shape_image)\n",
    "base_model.trainable=False\n",
    "base_model_output = base_model(input_image, training=False)\n",
    "layer_global_pooling = keras.layers.GlobalAveragePooling2D(name=\"pretrained_global_avg_pooling\")(base_model_output)\n",
    "out_dense_1 = keras.layers.Dense(64, name =\"output_dense_img_1\",activation=\"relu\")(layer_global_pooling)  \n",
    "bn_out_1 = keras.layers.BatchNormalization()(out_dense_1)\n",
    "dropout_img_1 = keras.layers.Dropout(0.5, name=\"dropout_img_1\")(bn_out_1)\n",
    "out_dense_2 = keras.layers.Dense(16, name =\"output_dense_img_2\",activation=\"relu\")(dropout_img_1)  \n",
    "# out_image = keras.layers.Dense(16, name =\"output_image\",activation=\"relu\")(dropout_img_2)  \n",
    "\n",
    "########## Tabular Input ##########\n",
    "tabular_inp= keras.layers.Input(shape=(8,))\n",
    "# Concat - Image and Tabular\n",
    "concat = keras.layers.Concatenate(name=\"concat\")([out_dense_2, tabular_inp])\n",
    "concat_out_1 = keras.layers.Dense(64, name=\"concat_out_2\", activation=\"relu\",\n",
    "                                 kernel_regularizer=keras.regularizers.l2(0.1)\n",
    "                                 )(concat)\n",
    "bn_out_2 = keras.layers.BatchNormalization()(concat_out_1)\n",
    "drop_out_img_tab_1 = keras.layers.Dropout(0.25, name=\"dropout_img_tab_2\")(bn_out_2)\n",
    "concat_out_2 = keras.layers.Dense(32, name=\"concat_out_3\", activation=\"relu\")(drop_out_img_tab_1)\n",
    "p1 = keras.layers.Dense(3, activation=\"linear\", name=\"p1\")(concat_out_2)\n",
    "p2 = keras.layers.Dense(3, activation=\"relu\", name=\"p2\")(concat_out_2)\n",
    "preds = keras.layers.Lambda(lambda x: x[0] + tf.cumsum(x[1], axis=1), \n",
    "                 name=\"preds\")([p1, p2])\n",
    "\n",
    "model = keras.Model(inputs = [input_image, tabular_inp], outputs = preds)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "print(model.summary())\n",
    "print(f\" N Layers of BASE model --> {len(base_model.layers)}\")\n",
    "print(f\" N Layers of our model --> {len(model.layers)}\")\n",
    "for index, layer in enumerate(model.layers):\n",
    "    print(index, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"xception\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_19 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 111, 111, 32) 864         input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 111, 111, 32) 128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 111, 111, 32) 0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 109, 109, 64) 18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 109, 109, 64) 256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 109, 109, 64) 0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 109, 109, 128 8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 109, 109, 128 512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 109, 109, 128 0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 109, 109, 128 17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 109, 109, 128 512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 55, 55, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 55, 55, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 55, 55, 128)  512         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_48 (Add)                    (None, 55, 55, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 55, 55, 128)  0           add_48[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 55, 55, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 55, 55, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 55, 55, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 55, 55, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 55, 55, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 28, 28, 256)  32768       add_48[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 28, 28, 256)  1024        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_49 (Add)                    (None, 28, 28, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 28, 28, 256)  0           add_49[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 28, 28, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 28, 28, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 28, 28, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 28, 28, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 28, 28, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 14, 14, 728)  186368      add_49[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 728)  0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 14, 14, 728)  2912        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_50 (Add)                    (None, 14, 14, 728)  0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 14, 14, 728)  0           add_50[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 14, 14, 728)  0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 14, 14, 728)  0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_51 (Add)                    (None, 14, 14, 728)  0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_50[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 14, 14, 728)  0           add_51[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 14, 14, 728)  0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 14, 14, 728)  0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_52 (Add)                    (None, 14, 14, 728)  0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_51[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 14, 14, 728)  0           add_52[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 14, 14, 728)  0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 14, 14, 728)  0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_53 (Add)                    (None, 14, 14, 728)  0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_52[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 14, 14, 728)  0           add_53[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 14, 14, 728)  0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 14, 14, 728)  0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_54 (Add)                    (None, 14, 14, 728)  0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_53[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 14, 14, 728)  0           add_54[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 14, 14, 728)  0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 14, 14, 728)  0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_55 (Add)                    (None, 14, 14, 728)  0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_54[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 14, 14, 728)  0           add_55[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 14, 14, 728)  536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 14, 14, 728)  2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 14, 14, 728)  0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 14, 14, 728)  536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 14, 14, 728)  2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 14, 14, 728)  0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 14, 14, 728)  536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 14, 14, 728)  2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_56 (Add)                    (None, 14, 14, 728)  0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_55[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 14, 14, 728)  0           add_56[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 14, 14, 728)  536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 14, 14, 728)  2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 14, 14, 728)  0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 14, 14, 728)  536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 14, 14, 728)  2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 14, 14, 728)  0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 14, 14, 728)  536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 14, 14, 728)  2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_57 (Add)                    (None, 14, 14, 728)  0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_56[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 14, 14, 728)  0           add_57[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 14, 14, 728)  536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 14, 14, 728)  2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 14, 14, 728)  0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 14, 14, 728)  536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 14, 14, 728)  2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 14, 14, 728)  0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 14, 14, 728)  536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 14, 14, 728)  2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_58 (Add)                    (None, 14, 14, 728)  0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_57[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 14, 14, 728)  0           add_58[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 14, 14, 728)  536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 14, 14, 728)  2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 14, 14, 728)  0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 14, 14, 1024) 752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 14, 14, 1024) 4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 7, 7, 1024)   745472      add_58[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 7, 7, 1024)   0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 7, 7, 1024)   4096        conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_59 (Add)                    (None, 7, 7, 1024)   0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 7, 7, 1536)   1582080     add_59[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 7, 7, 1536)   6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 7, 7, 1536)   0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 7, 7, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 7, 7, 2048)   8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 7, 7, 2048)   0           block14_sepconv2_bn[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 20,861,480\n",
      "Trainable params: 3,163,648\n",
      "Non-trainable params: 17,697,832\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N layers in base model --> 132\n",
      "Freezing Top 4 layers\n"
     ]
    }
   ],
   "source": [
    "trainable = 4\n",
    "base_model.trainable=True\n",
    "print(f\"N layers in base model --> {len(base_model.layers)}\")\n",
    "print(f\"Freezing Top {trainable} layers\")\n",
    "for layer in base_model.layers[:(len(base_model.layers) - trainable)]:\n",
    "        layer.trainable = False\n",
    "for layer in base_model.layers[(len(base_model.layers) - trainable):]:\n",
    "    layer.trainable = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Image_Input (InputLayer)        [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "xception (Model)                (None, 7, 7, 2048)   20861480    Image_Input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "pretrained_global_avg_pooling ( (None, 2048)         0           xception[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "output_dense_img_1 (Dense)      (None, 64)           131136      pretrained_global_avg_pooling[0][\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 64)           256         output_dense_img_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_img_1 (Dropout)         (None, 64)           0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "output_dense_img_2 (Dense)      (None, 16)           1040        dropout_img_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "input_20 (InputLayer)           [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concat (Concatenate)            (None, 24)           0           output_dense_img_2[0][0]         \n",
      "                                                                 input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concat_out_2 (Dense)            (None, 64)           1600        concat[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 64)           256         concat_out_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_img_tab_2 (Dropout)     (None, 64)           0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concat_out_3 (Dense)            (None, 32)           2080        dropout_img_tab_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "p1 (Dense)                      (None, 3)            99          concat_out_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "p2 (Dense)                      (None, 3)            99          concat_out_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "preds (Lambda)                  (None, 3)            0           p1[0][0]                         \n",
      "                                                                 p2[0][0]                         \n",
      "==================================================================================================\n",
      "Total params: 20,998,046\n",
      "Trainable params: 3,299,958\n",
      "Non-trainable params: 17,698,088\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.SGD(lr=1e-5, momentum=0.9)\n",
    "model.compile(loss=mloss(0.8), optimizer=optimizer, metrics=[score])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr_callback():\n",
    "    lr_start   = 0.1\n",
    "    lr_max     = 0.1\n",
    "    lr_min     = 0.00001\n",
    "    lr_ramp_ep = 10\n",
    "    lr_sus_ep  = 0\n",
    "    lr_decay   = 0.8\n",
    "   \n",
    "    def lrfn(epoch):\n",
    "        if epoch < lr_ramp_ep:\n",
    "            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n",
    "            \n",
    "        elif epoch < lr_ramp_ep + lr_sus_ep:\n",
    "            lr = lr_max\n",
    "            \n",
    "        else:\n",
    "            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n",
    "            \n",
    "        return lr\n",
    "\n",
    "    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=False)\n",
    "    return lr_callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile for fold = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape --> (1339, 11)\n",
      "Number of unique patients in Train --> 153\n",
      "Validation Shape --> (143, 11)\n",
      "Number of unique patients in Validation --> 16\n",
      "Epoch 1/5\n",
      "41/41 [==============================] - 1746s 43s/step - loss: 395.8427 - score: 9.3513 - val_loss: 205.9217 - val_score: 8.3790 - lr: 0.1000\n",
      "Epoch 2/5\n",
      "41/41 [==============================] - 1782s 43s/step - loss: 271.2944 - score: 8.3280 - val_loss: 220.1334 - val_score: 8.0426 - lr: 0.1000\n",
      "Epoch 3/5\n",
      "41/41 [==============================] - 1723s 42s/step - loss: 267.9742 - score: 8.2780 - val_loss: 286.6303 - val_score: 8.5090 - lr: 0.1000\n",
      "8/8 [==============================] - 94s 12s/step - loss: 205.9217 - score: 8.3790\n",
      "Validation Data Score --> [205.92173767089844, 8.37901782989502]\n"
     ]
    }
   ],
   "source": [
    "# def run(model, fold):\n",
    "fold = 0\n",
    "    # read folds data and get train & validation data \n",
    "df_folds = pd.read_csv(f\"{OUTPUT_PATH}/osic_10_folds.csv\")\n",
    "df_train = df_folds[df_folds.fold !=fold].reset_index(drop=True)\n",
    "df_train = df_train.sample(frac=1).reset_index(drop=True)\n",
    "print(f\"Train Shape --> {df_train.shape}\")\n",
    "print(f\"Number of unique patients in Train --> {df_train.Patient.nunique()}\")\n",
    "\n",
    "# get validation data\n",
    "df_valid = df_folds[df_folds.fold==fold].reset_index(drop=True)  \n",
    "print(f\"Validation Shape --> {df_valid.shape}\")\n",
    "print(f\"Number of unique patients in Validation --> {df_valid.Patient.nunique()}\")\n",
    "\n",
    "# compile model\n",
    "# lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=1)\n",
    "optimizer = keras.optimizers.Adam(lr=0.05)\n",
    "model.compile(loss=mloss(0.8), \n",
    "          optimizer=optimizer, metrics=[score])\n",
    "\n",
    "# check point and early stopping\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(f\"/Users/paritoshgupta/Desktop/osic_models/osic_fold_{fold}.h5\",\n",
    "                                                save_best_only=True)\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True)\n",
    "\n",
    "# fit model \n",
    "\n",
    "history = model.fit(DataGenerator(dataset=df_train, batch_size=32, aug=True, shuffle=False),\n",
    "                    validation_data=DataGenerator(dataset=df_valid, batch_size=32, aug=False, shuffle=False), \n",
    "                    epochs=5,\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb, get_lr_callback()])\n",
    "# save model \n",
    "model.save(f\"/Users/paritoshgupta/Desktop/osic_models/test_model.h5\")\n",
    "\n",
    "# print validation data score\n",
    "print(f\"Validation Data Score --> {model.evaluate(DataGenerator(dataset=df_valid, batch_size=16, aug=False, shuffle=False))}\")\n",
    "\n",
    "# return model via UDF\n",
    "# return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44, 10)\n",
      "11/11 [==============================] - 57s 5s/step - loss: 180.4018 - score: 8.3044\n",
      "Test Data Score --> [180.40184020996094, 8.304366111755371]\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv(f\"{OUTPUT_PATH}/osic_test.csv\")\n",
    "print(df_test.shape)\n",
    "# df_test\n",
    "print(f\"Test Data Score --> {model.evaluate(DataGenerator(dataset=df_test, batch_size=4, aug=False, shuffle=False))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1120.6364, 1379.5336, 2179.7068],\n",
       "       [1448.4658, 1782.8522, 2817.1238],\n",
       "       [1407.4906, 1732.5883, 2737.5574],\n",
       "       [1386.048 , 1706.1971, 2695.9404],\n",
       "       [1540.7133, 1896.422 , 2996.5154],\n",
       "       [1672.2847, 2058.2146, 3251.9846],\n",
       "       [1456.744 , 1793.103 , 2833.614 ],\n",
       "       [1310.0302, 1612.6813, 2548.713 ],\n",
       "       [1684.0947, 2072.8123, 3275.2063],\n",
       "       [1651.7823, 2032.9554, 3212.5076],\n",
       "       [1816.819 , 2236.1318, 3533.666 ],\n",
       "       [1429.441 , 1759.4077, 2780.2961]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_output_single = y_output.mean(axis=0)\n",
    "y_output_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2315., 2214., 2061., ..., 3364., 3240., 3303.])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_output_single.shape\n",
    "np.array(df_test.FVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-446c9ada66c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFVC\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my_output_single\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-79aae78b87c5>\u001b[0m in \u001b[0;36mscore\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0msigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m     \u001b[0mfvc_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "score([df_test.FVC], [y_output_single])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = run(model, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 153\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in base_model.layers[fine_tune_at:]:\n",
    "    layer.trainable = True\n",
    "    \n",
    "optimizer = keras.optimizers.Adam(lr=0.0025, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "model.compile(loss=mloss(0.8), \n",
    "          optimizer=optimizer, metrics=[score])\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_fine = model.fit(DataGenerator(dataset=df_train),\n",
    "                    validation_data=DataGenerator(dataset=df_valid), epochs=20,\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb],\n",
    "                   initial_epoch=history.epoch[-1])\n",
    "print(f\" Validation Data Score --> {model.evaluate(DataGenerator(dataset=df_valid))}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "save_fig(\"keras_learning_curves_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Load model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\"/Users/paritoshgupta/Desktop/osic_models/\")\n",
    "\n",
    "# model = keras.models.load_model(\"my_keras_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Layer (type)                    Output Shape         Param #     Connected to                     \n",
    "==================================================================================================\n",
    "Image_Input (InputLayer)        [(None, 224, 224, 3) 0                                            \n",
    "__________________________________________________________________________________________________\n",
    "xception (Model)                (None, 7, 7, 2048)   20861480    Image_Input[0][0]                \n",
    "__________________________________________________________________________________________________\n",
    "pretrained_global_avg_pooling ( (None, 2048)         0           xception[1][0]                   \n",
    "__________________________________________________________________________________________________\n",
    "dropout_img_1 (Dropout)         (None, 2048)         0           pretrained_global_avg_pooling[0][\n",
    "__________________________________________________________________________________________________\n",
    "output_class (Dense)            (None, 32)           65568       dropout_img_1[0][0]              \n",
    "__________________________________________________________________________________________________\n",
    "input_2 (InputLayer)            [(None, 8)]          0                                            \n",
    "__________________________________________________________________________________________________\n",
    "concat (Concatenate)            (None, 40)           0           output_class[0][0]               \n",
    "                                                                 input_2[0][0]                    \n",
    "__________________________________________________________________________________________________\n",
    "concat_out_2 (Dense)            (None, 64)           2624        concat[0][0]                     \n",
    "__________________________________________________________________________________________________\n",
    "dropout_img_tab_2 (Dropout)     (None, 64)           0           concat_out_2[0][0]               \n",
    "__________________________________________________________________________________________________\n",
    "concat_out_3 (Dense)            (None, 32)           2080        dropout_img_tab_2[0][0]          \n",
    "__________________________________________________________________________________________________\n",
    "p1 (Dense)                      (None, 3)            99          concat_out_3[0][0]               \n",
    "__________________________________________________________________________________________________\n",
    "p2 (Dense)                      (None, 3)            99          concat_out_3[0][0]               \n",
    "__________________________________________________________________________________________________\n",
    "preds (Lambda)                  (None, 3)            0           p1[0][0]                         \n",
    "                                                                 p2[0][0]                         \n",
    "============================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(base_model.layers)\n",
    "# base_model.summary()\n",
    "# keras.optimizers.RMSprop()\n",
    "\n",
    "0.001/1e-4\n",
    "\n",
    "# 1e-4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(base_model.layers)\n",
    "model.compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_39 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x7ff3e653ba90>,\n",
       " <tensorflow.python.keras.layers.convolutional.ZeroPadding2D at 0x7ff3e446b490>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff3e29a7a90>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7ff3e2a14390>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7ff3e671b090>,\n",
       " <tensorflow.python.keras.layers.convolutional.ZeroPadding2D at 0x7ff3e66fe450>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7ff3e66fe4d0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff3e6757050>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7ff3e6776750>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7ff3e677a050>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff3e5e02450>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7ff3e5e2f6d0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7ff3e5e33f50>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff3e6743810>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff3e5e33e50>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7ff3e6749950>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7ff3e5e5de90>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7ff3e5e66450>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7ff3e5e6a890>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff3e5e8e810>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7ff3e5e94610>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7ff3e5e9cdd0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff3e5e9fc90>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7ff3e5eccf50>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7ff3e5ed2090>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff3e5ed6490>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7ff3e5f03710>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7ff3e5f08250>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7ff3e5f08f10>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff3e5f090d0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7ff3e5f39910>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7ff3e5f49050>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff3e5f42310>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7ff3e5f67b10>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7ff3e5f70b90>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff3e5f74d10>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7ff3e5f9db50>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7ff3e5fa3110>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7ff3e5fa8550>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff3e5fdc2d0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7ff3e60044d0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7ff3e6009e10>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff3e600ecd0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7ff3e603cb10>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7ff3e69000d0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff3e5fa85d0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff3e6906710>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7ff3e5fd4f50>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7ff3e6932750>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7ff3e6933290>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7ff3e6933f10>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff3e693a0d0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7ff3e69f8910>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7ff3e6a07050>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff3e6a02310>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7ff3e6ca7b10>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7ff3e6cafb90>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff3e6cb3d10>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7ff3e6d20b50>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7ff3e6d23110>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7ff3e6d29550>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff3e6d295d0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7ff3e6e24f50>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7ff3e6e2b2d0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff3e6e2f710>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7ff3e6e5a9d0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7ff3e6e62610>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff3e6e6e050>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7ff3e6e8ab90>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7ff3e6e92750>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7ff3e6e96b90>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff3e6e96c10>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7ff3e6ee24d0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7ff3e6f0bfd0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff3e6f0efd0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7ff3e7006fd0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7ff3e7010390>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff3e7013790>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7ff3e70d1a50>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7ff3e70d66d0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7ff3e70e0110>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff3e714b890>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7ff3e7175b90>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7ff3e717d310>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff3e7182750>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7ff3e71ada10>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7ff3e71b2910>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff3e70db390>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff3e71bc050>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7ff3e7147c10>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7ff3e88ade10>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7ff3e88b3790>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7ff3e88b7bd0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff3e88b7c50>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7ff3e88ea610>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7ff3e88ec550>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff3e88f2c10>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7ff3e8918e10>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7ff3e891f3d0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff3e89237d0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7ff3e894fa90>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7ff3e895f0d0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7ff3e8959490>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff3e8959290>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7ff3e8987c50>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7ff3e898ab50>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff3ed8003d0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7ff3ed82d6d0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7ff3ed831f50>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff3ed831e50>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7ff3ed85ae90>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7ff3ed863450>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7ff3ed867890>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff3f098c810>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7ff3f0992610>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7ff3f0998dd0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff3f099ec90>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7ff3f09c7f50>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7ff3f09cf090>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff3f09d3490>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7ff3f09ff750>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7ff3f1643290>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7ff3f1643f50>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff3f164a090>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7ff3f1676910>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7ff3f1686050>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff3f1681310>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7ff3f16a8b10>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7ff3f16aeb90>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff3f16b2d10>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7ff3f16deb50>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7ff3f16e6110>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7ff3f16e8550>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff3f16e85d0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7ff3f52d6f50>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7ff3f52d82d0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff3f52df710>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7ff3f5a4b9d0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7ff3f5a50610>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff3f5a5b050>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7ff3f5a7db90>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7ff3f5cc3750>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7ff3f5cc8b90>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff3f5cfbdd0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7ff3f6622c10>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7ff3f663b050>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff3f6634c90>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7ff3f685ab50>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7ff3f6862710>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff3f5cc8c10>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff3f6866b50>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7ff3f5cfb910>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7ff3f6891bd0>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7ff3f6897190>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7ff3f689b5d0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff3fd2115d0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7ff3fd21af90>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7ff3fd220350>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff3fd222790>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7ff3fd650a50>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7ff3fd6546d0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff3fd65e0d0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7ff3fd67fc50>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7ff3fd689810>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7ff3fd68dc50>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff3fd68dcd0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7ff3fdfbd690>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7ff3fdfc2f50>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff3fdfc2e50>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7ff3fe91de90>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7ff3fe926450>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7ff3fe92b890>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7ff3ff255b50>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7ff3ff268150>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7ff3ff260550>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,43,5]\n",
    "np.random.shuffle(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1, 5, 43]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.applications.xception.Xception(weights=\"imagenet\", include_top=False,\n",
    "                input_tensor=keras.layers.Input(shape=input_shape_image))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Hide code",
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "265.014px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
