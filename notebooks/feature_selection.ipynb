{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Based on variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import VarianceThreshold\n",
    "# data = ...\n",
    "# var_thresh = VarianceThreshold(threshold=0.1)\n",
    "# transformed_data = var_thresh.fit_transform(data)\n",
    "# # transformed data will have columns with >=0.1 variance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Based on correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedInc_sqrt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MedInc</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.119034</td>\n",
       "      <td>0.326895</td>\n",
       "      <td>-0.062040</td>\n",
       "      <td>0.004834</td>\n",
       "      <td>0.018766</td>\n",
       "      <td>-0.079809</td>\n",
       "      <td>-0.015176</td>\n",
       "      <td>0.984329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HouseAge</th>\n",
       "      <td>-0.119034</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.153277</td>\n",
       "      <td>-0.077747</td>\n",
       "      <td>-0.296244</td>\n",
       "      <td>0.013191</td>\n",
       "      <td>0.011173</td>\n",
       "      <td>-0.108197</td>\n",
       "      <td>-0.132797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AveRooms</th>\n",
       "      <td>0.326895</td>\n",
       "      <td>-0.153277</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.847621</td>\n",
       "      <td>-0.072213</td>\n",
       "      <td>-0.004852</td>\n",
       "      <td>0.106389</td>\n",
       "      <td>-0.027540</td>\n",
       "      <td>0.326688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AveBedrms</th>\n",
       "      <td>-0.062040</td>\n",
       "      <td>-0.077747</td>\n",
       "      <td>0.847621</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.066197</td>\n",
       "      <td>-0.006181</td>\n",
       "      <td>0.069721</td>\n",
       "      <td>0.013344</td>\n",
       "      <td>-0.066910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Population</th>\n",
       "      <td>0.004834</td>\n",
       "      <td>-0.296244</td>\n",
       "      <td>-0.072213</td>\n",
       "      <td>-0.066197</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069863</td>\n",
       "      <td>-0.108785</td>\n",
       "      <td>0.099773</td>\n",
       "      <td>0.018415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AveOccup</th>\n",
       "      <td>0.018766</td>\n",
       "      <td>0.013191</td>\n",
       "      <td>-0.004852</td>\n",
       "      <td>-0.006181</td>\n",
       "      <td>0.069863</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002366</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>0.015266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Latitude</th>\n",
       "      <td>-0.079809</td>\n",
       "      <td>0.011173</td>\n",
       "      <td>0.106389</td>\n",
       "      <td>0.069721</td>\n",
       "      <td>-0.108785</td>\n",
       "      <td>0.002366</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.924664</td>\n",
       "      <td>-0.084303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Longitude</th>\n",
       "      <td>-0.015176</td>\n",
       "      <td>-0.108197</td>\n",
       "      <td>-0.027540</td>\n",
       "      <td>0.013344</td>\n",
       "      <td>0.099773</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>-0.924664</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.015569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MedInc_sqrt</th>\n",
       "      <td>0.984329</td>\n",
       "      <td>-0.132797</td>\n",
       "      <td>0.326688</td>\n",
       "      <td>-0.066910</td>\n",
       "      <td>0.018415</td>\n",
       "      <td>0.015266</td>\n",
       "      <td>-0.084303</td>\n",
       "      <td>-0.015569</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  \\\n",
       "MedInc       1.000000 -0.119034  0.326895  -0.062040    0.004834  0.018766   \n",
       "HouseAge    -0.119034  1.000000 -0.153277  -0.077747   -0.296244  0.013191   \n",
       "AveRooms     0.326895 -0.153277  1.000000   0.847621   -0.072213 -0.004852   \n",
       "AveBedrms   -0.062040 -0.077747  0.847621   1.000000   -0.066197 -0.006181   \n",
       "Population   0.004834 -0.296244 -0.072213  -0.066197    1.000000  0.069863   \n",
       "AveOccup     0.018766  0.013191 -0.004852  -0.006181    0.069863  1.000000   \n",
       "Latitude    -0.079809  0.011173  0.106389   0.069721   -0.108785  0.002366   \n",
       "Longitude   -0.015176 -0.108197 -0.027540   0.013344    0.099773  0.002476   \n",
       "MedInc_sqrt  0.984329 -0.132797  0.326688  -0.066910    0.018415  0.015266   \n",
       "\n",
       "             Latitude  Longitude  MedInc_sqrt  \n",
       "MedInc      -0.079809  -0.015176     0.984329  \n",
       "HouseAge     0.011173  -0.108197    -0.132797  \n",
       "AveRooms     0.106389  -0.027540     0.326688  \n",
       "AveBedrms    0.069721   0.013344    -0.066910  \n",
       "Population  -0.108785   0.099773     0.018415  \n",
       "AveOccup     0.002366   0.002476     0.015266  \n",
       "Latitude     1.000000  -0.924664    -0.084303  \n",
       "Longitude   -0.924664   1.000000    -0.015569  \n",
       "MedInc_sqrt -0.084303  -0.015569     1.000000  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "data = fetch_california_housing()\n",
    "X = data[\"data\"]\n",
    "col_names = data[\"feature_names\"]\n",
    "y = data[\"target\"]\n",
    "\n",
    "# convert to pandas dataframe\n",
    "df = pd.DataFrame(X, columns=col_names)\n",
    "# introduce a highly correlated column\n",
    "df.loc[:, \"MedInc_sqrt\"] = df.MedInc.apply(np.sqrt)\n",
    "\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate feature selection (UFS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Univariate feature selection is nothing but a scoring of each feature against a given target\n",
    "\n",
    "- ANOVA, F-test, chi^2 are some of the popular methods for doing univariate feature selection\n",
    "\n",
    "- There are two ways of using these in sklearn:\n",
    "    \n",
    "    - SelectKBest: It keeps the top k-scoring features\n",
    "    - SelectPercentile: It keeps the top features which are in a percentage specified by the user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UFS Wrapper for any problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 2)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "\n",
    "\n",
    "class UnivariateFeatureSelection:\n",
    "    def __init__(self, n_features, problem_type, scoring):\n",
    "        \"\"\"\n",
    "        Custom univariate feature selection wrapper on different univariate\n",
    "            feature selection models from sklearn\n",
    "        :param n_features: SelectPercentile if float else SelectKBest\n",
    "        :param problem_type: classification or regression\n",
    "        :param scoring: scoring function, string\n",
    "        \"\"\"\n",
    "        \n",
    "        # for a given problem type, there are only a few valid scoring methods\n",
    "        # extend this with your own custom methods if required\n",
    "        if problem_type == \"classification\":\n",
    "            valid_scoring = {\"f_classif\": f_classif,\n",
    "                            \"chi2\": chi2,\n",
    "                            \"mutual_info_classif\": mutual_info_classif}\n",
    "        else:\n",
    "            valid_scoring = {\"f_regression\": f_regression,\n",
    "                            \"mutual_info_regression\": mutual_info_regression}\n",
    "        \n",
    "        # raise exception if there is no valid scoring method:\n",
    "        if scoring not in valid_scoring:\n",
    "            raise Exception(\"Invalid scoring function\")\n",
    "            \n",
    "        # if n_features in int, we select KBest\n",
    "        # if n_features is float, we select SelectPercentile\n",
    "        # please note that it is int in both cases in sklearn\n",
    "        if isinstance(n_features, int):\n",
    "            self.selection = SelectKBest(valid_scoring[scoring], k=n_features)\n",
    "        elif isinstance(n_features, float):\n",
    "            self.selection = SelectPercentile(valid_scoring[scoring], percentile=int(n_features * 100))\n",
    "        else:\n",
    "            raise Exception(\"Invalid type of feature\")\n",
    "        \n",
    "    # same fit function\n",
    "    def fit(self, X, y):\n",
    "        return self.selection.fit(X,y)\n",
    "\n",
    "    # same transform function\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.selection.transform(X)\n",
    "\n",
    "    # same fit transform function\n",
    "    def fit_transform(self, X, y):\n",
    "        return self.selection.fit_transform(X, y)\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "data = fetch_california_housing()\n",
    "X = data[\"data\"]\n",
    "col_names = data[\"feature_names\"]\n",
    "y = data[\"target\"]\n",
    "\n",
    "ufs = UnivariateFeatureSelection(n_features=0.2, problem_type=\"regression\", scoring=\"f_regression\")\n",
    "ufs.fit(X, y)\n",
    "X_transformed = ufs.transform(X)\n",
    "# X_transformed\n",
    "X_transformed.shape   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection using ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greedy Feature Selection (GFS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The simplest form of feature selection that uses a model for selection is known as \"Greedy feature selection\"\n",
    "\n",
    "- In GFS, steps:\n",
    "\n",
    "    - the first step is to choose the model\n",
    "\n",
    "    - the second step is to select a loss/scoring function\n",
    "    \n",
    "    - the third and final step is to iteratively evaluate each feature and add it to a list of \"good\" features if it improves loss/score\n",
    "    \n",
    "**Note**:\n",
    "\n",
    "    - The feature selection process will fit a given model each time it evaluates a feature (reason, known as GFS)\n",
    "    \n",
    "    - The computational cost associated with GFS is very high and will take a lot of time for this kind of feature selection to finish\n",
    "    \n",
    "    - if we don't use this feature selection properly, we might end up overfitting the model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# greedy.py\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "class GreedyFeatureSelection:\n",
    "    \"\"\"\n",
    "    A simple and custom class for greedy feature selection\n",
    "    Can be customized for other type of problems\n",
    "    \"\"\"\n",
    "    \n",
    "    def evaluate_score(self, X, y):\n",
    "        \"\"\"\n",
    "        This function evaluates model on data and returns AUC\n",
    "        NOTE: we fit the data and calculate AUC on same data\n",
    "        WE ARE OVERFITTING HERE\n",
    "        But this is also a way to achieve greedy selection.\n",
    "        k-fold will take k times longer\n",
    "        \n",
    "        To implement the correct way, calculate OOF AUC and return mean AUC over k folds\n",
    "        :param X: training data\n",
    "        :param y: targets\n",
    "        :return: overfitted  area under the roc curve\n",
    "        \"\"\"\n",
    "        # fit the logistic regression model and calculate AUC on same data\n",
    "        # choose any model that suits the data\n",
    "        model = linear_model.LogisticRegression()\n",
    "        model.fit(X, y)\n",
    "        predictions = model.predict_proba(X)[:, 1]\n",
    "        auc = metrics.roc_auc_score(y, predictions)\n",
    "        return auc\n",
    "    \n",
    "    \n",
    "    def _feature_selection(self, X, y):\n",
    "        \"\"\"\n",
    "        This function does the actual greedy selection\n",
    "        :param X: data, numpy array\n",
    "        :param y: targets, numpy array\n",
    "        :return: (best scores, best features)\n",
    "        \"\"\"\n",
    "        \n",
    "        # initialize good features list and best features to keep track of both\n",
    "        good_features = []\n",
    "        best_scores = []\n",
    "        \n",
    "        # calculate the number of features\n",
    "        num_features = X.shape[1]\n",
    "        \n",
    "        # infinite loop\n",
    "        while True:\n",
    "            # initialize best feature and score of this loop\n",
    "            this_feature = None\n",
    "            best_score = 0\n",
    "            \n",
    "            # loop all features\n",
    "            for feature in range(num_features):\n",
    "                # if feature is already in good features, skip this for loop\n",
    "                if feature in good_features:\n",
    "                    continue\n",
    "                \n",
    "                # selected features are all good features and current feature\n",
    "                selected_features = good_features + [feature]\n",
    "                \n",
    "                # remove all other features from data\n",
    "                xtrain = X[:, selected_features]\n",
    "                \n",
    "                # calculate the score in our case AUC\n",
    "                score = self.evaluate_score(xtrain, y)\n",
    "                \n",
    "                # if score is greater than best_score of this loop, change best score and best feature\n",
    "                if score > best_score:\n",
    "                    this_feature = feature\n",
    "                    best_score = score\n",
    "                \n",
    "                # if we have selected a feature, add it to feature list and update best scores list\n",
    "                if this_feature!=None:\n",
    "                    good_features.append(this_feature)\n",
    "                    best_scores.append(best_score)\n",
    "                    \n",
    "                    \n",
    "                # if we didnt improvr during the previous round, exit the while loop\n",
    "                if len(best_scores)>2:\n",
    "                    if best_scores[-1] < best_scores[-2]:\n",
    "                        break\n",
    "                        \n",
    "        return best_scores[:-1], good_features[:-1]\n",
    "    \n",
    "    def __call__(self, X, y):\n",
    "        \"\"\"\n",
    "        call function will the class on a set of arguments\n",
    "        \"\"\"\n",
    "        # select features, return scores and selected indices\n",
    "        scores, features = self._feature_selection(X, y)\n",
    "        # transformed data with selected features\n",
    "        return X[:, features], scores\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    # generate binary classification data\n",
    "    X, y = make_classification(n_samples=1000, n_features=4)\n",
    "    print(f\"Original Shape --> {X.shape}\")\n",
    "    # transform data by greedy feature selection\n",
    "    X_transformed, scores = GreedyFeatureSelection()(X, y)\n",
    "    print(f\"Transformed Shape --> {X_transformed.shape}\")\n",
    "    # transform data by greedy feature selection\n",
    "    X_transformed, scores = GreedyFeatureSelection()(X, y)\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Feature Elimination (RFE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Another greedy approach is RFE\n",
    "- In RFE, we start with all features and keep removing one feature in very iteration that provides the least value to a given model\n",
    "- When we are doing recursive feature elimination, in each iteration, we remove the feature which has the feature importance or the feature which has a coefficient close to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640, 8)\n",
      "(20640, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# fetch a regression dataset\n",
    "data = fetch_california_housing()\n",
    "X = data[\"data\"]\n",
    "print(X.shape)\n",
    "col_names = data[\"feature_names\"]\n",
    "Y = data[\"target\"]\n",
    "\n",
    "# initialize the model \n",
    "model = LinearRegression()\n",
    "# initialize RFE\n",
    "rfe = RFE(estimator=model, n_features_to_select=3)\n",
    "\n",
    "# fit RFE\n",
    "rfe.fit(X, y)\n",
    "\n",
    "# get the transformed data with selected columns\n",
    "X_transformed = rfe.transform(X)\n",
    "print(X_transformed.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature importance using Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# fetch data\n",
    "data = load_diabetes()\n",
    "X = data[\"data\"]\n",
    "col_names = data[\"feature_names\"]\n",
    "y = data[\"target\"]\n",
    "\n",
    "# initialize the model\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X, y)\n",
    "\n",
    "# feature importance from random forest model\n",
    "importances = model.feature_importances_\n",
    "idxs = np.argsort(importances)\n",
    "plt.title('Feature Importance')\n",
    "plt.barh(range(len(idxs)), importances[idxs], align ='center')\n",
    "plt.yticks(range(len(idxs)), [col_names[i] for i in idxs])\n",
    "plt.xlabel(\"Random Forest Feature Importance\")\n",
    "plt.show()\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SelectFromModel class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Scikit-learn also offers SelectFromModel class that helps you choose features directly from a given model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bmi', 's5']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# fetch regression dataset\n",
    "data = load_diabetes()\n",
    "X = data[\"data\"]\n",
    "col_names = data[\"feature_names\"]\n",
    "y = data[\"target\"]\n",
    "\n",
    "# initialize the model\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "# select from model\n",
    "sfm = SelectFromModel(estimator=model)\n",
    "X_transformed = sfm.fit_transform(X, y)\n",
    "\n",
    "# see which features are selected\n",
    "support = sfm.get_support()\n",
    "\n",
    "# get feature names\n",
    "print([x for x, y in zip(col_names, support) if y ==True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
